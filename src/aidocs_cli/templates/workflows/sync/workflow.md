---
name: docs-sync
description: Generate embeddings and SQL for syncing documentation to PostgreSQL vector database
---

# Documentation Sync Workflow

**Goal:** Generate embeddings for documentation chunks and create a SQL script for importing to PostgreSQL.

**Your Role:** You are a sync coordinator. You will read chunk files, call OpenAI for embeddings, and generate a SQL script.

**Requires:**
- `docs/.chunks/manifest.json` from `aidocs chunk`
- Environment variable `OPENAI_API_KEY`

---

## ARGUMENTS PARSING

Parse the arguments:
```
/docs:sync [--dry] [--force]
```

Examples:
```
/docs:sync                    # Generate sync SQL (smart)
/docs:sync --dry              # Preview what would be synced
/docs:sync --force            # Re-sync all (ignore last-sync)
```

---

## STEP 1: CHECK PREREQUISITES

### 1.1 Verify Chunks Exist

Check if `docs/.chunks/manifest.json` exists:

```
üîç Checking for chunked documentation...

‚ñ° Manifest file    ‚Üí Looking for docs/.chunks/manifest.json
```

If not found:
```
‚ùå No chunked documentation found.

Run `aidocs chunk` first to create chunk files.
```

### 1.2 Load Manifest

Read `docs/.chunks/manifest.json`:

```
‚úì Manifest found

Files tracked: 8
Last chunked: 2024-01-15 10:30:00
```

### 1.3 Check OpenAI API Key

Verify `OPENAI_API_KEY` is set:

```
‚úì OpenAI API key configured
```

If not found:
```
‚ùå OPENAI_API_KEY not set.

Set the environment variable:
   export OPENAI_API_KEY=sk-...
```

---

## STEP 2: DETERMINE CHANGES

### 2.1 Load Last Sync State

Read `docs/.chunks/last-sync.json` (if exists):

```json
{
  "synced_at": "2024-01-15T10:30:00Z",
  "files": {
    "docs/users/lifecycle.md": "sha256:abc123..."
  }
}
```

### 2.2 Compare with Manifest

For each file in manifest, compare hashes:

```
üìä Analyzing changes...

Unchanged (skip embeddings):
  ‚óã docs/users/lifecycle.md
  ‚óã docs/users/index.md

Changed (re-generate embeddings):
  ‚Üª docs/campaigns/lifecycle.md (3 chunks)

New (generate embeddings):
  + docs/orders/lifecycle.md (5 chunks)
  + docs/orders/index.md (2 chunks)

Deleted (remove from DB):
  - docs/old-page/removed.md
```

### 2.3 Calculate Stats

```
üìä Sync Summary:
   Unchanged: 2 files (skipped)
   Changed: 1 file (3 chunks)
   New: 2 files (7 chunks)
   Deleted: 1 file

   Embeddings to generate: 10
   Estimated tokens: ~5,000
   Estimated cost: ~$0.002
```

---

## STEP 3: DRY RUN (if --dry)

If `--dry` flag provided:

```
üìã DRY RUN - Preview Only

Would generate embeddings for 10 chunks
Would create SQL with:
  - 1 DELETE statement (for deleted file)
  - 1 DELETE statement (for changed file)
  - 10 INSERT statements

No files written.
Run without --dry to generate sync.sql
```

Exit here if dry run.

---

## STEP 4: GENERATE EMBEDDINGS

### 4.1 Read Chunk Files

For each new/changed file, read its `.chunks.json`:

```
üìö Loading chunks...

  docs/campaigns/lifecycle.chunks.json (3 chunks)
  docs/orders/lifecycle.chunks.json (5 chunks)
  docs/orders/index.chunks.json (2 chunks)

Total: 10 chunks to embed
```

### 4.2 Call OpenAI Embeddings API

For each chunk, call OpenAI API:

```
üîÑ Generating embeddings...

  [1/10] docs/campaigns/lifecycle.md#Overview
  [2/10] docs/campaigns/lifecycle.md#Creating
  [3/10] docs/campaigns/lifecycle.md#Editing
  ...
  [10/10] docs/orders/index.md#Related

‚úì All embeddings generated
  Tokens used: 4,832
  Cost: $0.0019
```

**API Call Template:**

Use WebFetch to call OpenAI:
```
POST https://api.openai.com/v1/embeddings
Headers:
  Authorization: Bearer $OPENAI_API_KEY
  Content-Type: application/json

Body:
{
  "model": "text-embedding-3-small",
  "input": "chunk content here..."
}
```

---

## STEP 5: GENERATE SQL SCRIPT

### 5.1 Create SQL File

Generate `docs/.chunks/sync.sql`:

```sql
-- Documentation Sync SQL
-- Generated by /docs:sync at 2024-01-15T11:00:00Z
-- Run with: psql $DATABASE_URL -f docs/.chunks/sync.sql

BEGIN;

-- Delete chunks for removed files
DELETE FROM doc_embeddings WHERE file_path = 'docs/old-page/removed.md';

-- Delete chunks for changed files (will re-insert below)
DELETE FROM doc_embeddings WHERE file_path = 'docs/campaigns/lifecycle.md';

-- Insert new/updated chunks
INSERT INTO doc_embeddings (file_path, content, chunk_index, title, metadata, file_hash, embedding)
VALUES (
  'docs/campaigns/lifecycle.md',
  'This guide covers the complete lifecycle of a campaign...',
  0,
  'Overview',
  '{"hierarchy": ["Campaigns", "Lifecycle"], "has_code": false, "has_images": true}'::jsonb,
  'sha256:def456...',
  '[0.0023, -0.0145, 0.0089, ...]'::vector
);

INSERT INTO doc_embeddings (file_path, content, chunk_index, title, metadata, file_hash, embedding)
VALUES (
  'docs/campaigns/lifecycle.md',
  '## Creating a Campaign\n\nFrom the campaigns list...',
  1,
  'Creating a Campaign',
  '{"hierarchy": ["Campaigns", "Lifecycle", "Creating a Campaign"], "has_code": false, "has_images": true}'::jsonb,
  'sha256:def456...',
  '[0.0045, -0.0178, 0.0112, ...]'::vector
);

-- ... more INSERT statements

COMMIT;

-- Summary:
-- Deleted: 2 file(s)
-- Inserted: 10 chunk(s)
```

### 5.2 SQL Formatting Notes

- Escape single quotes in content: `'` ‚Üí `''`
- Format embedding as vector: `'[0.001, 0.002, ...]'::vector`
- Format metadata as JSONB: `'{...}'::jsonb`
- Use transaction (BEGIN/COMMIT) for atomicity

---

## STEP 6: UPDATE LAST-SYNC

Create/update `docs/.chunks/last-sync.json`:

```json
{
  "synced_at": "2024-01-15T11:00:00Z",
  "files": {
    "docs/users/lifecycle.md": "sha256:abc123...",
    "docs/users/index.md": "sha256:bcd234...",
    "docs/campaigns/lifecycle.md": "sha256:def456...",
    "docs/orders/lifecycle.md": "sha256:efg567...",
    "docs/orders/index.md": "sha256:fgh678..."
  }
}
```

---

## STEP 7: COMPLETION

```
‚úÖ Sync SQL Generated

üìÑ Output: docs/.chunks/sync.sql

üìä Summary:
   Embeddings generated: 10
   DELETE statements: 2
   INSERT statements: 10
   Tokens used: 4,832
   Estimated cost: $0.002

üìã Next step:
   Run the SQL to update your database:

   psql $DATABASE_URL -f docs/.chunks/sync.sql

   Or copy and run in your preferred SQL client.
```

---

## ERROR HANDLING

| Error | Action |
|-------|--------|
| No manifest | Prompt to run `aidocs chunk` first |
| No API key | Show how to set OPENAI_API_KEY |
| API rate limit | Wait and retry with backoff |
| API error | Show error, suggest checking key/quota |
| Empty chunks | Skip with warning |

---

## NOTES

### Embedding Model

Using `text-embedding-3-small`:
- 1536 dimensions
- ~$0.02 per 1M tokens
- Good balance of quality/cost

### Incremental Sync

The workflow only generates embeddings for:
- New files (not in last-sync.json)
- Changed files (hash differs from last-sync.json)

Unchanged files are skipped to save API costs.

### Manual SQL Execution

SQL is generated as a file rather than executed directly because:
- No DB connection needed from Claude
- User can review before running
- Works with any PostgreSQL setup
- Easy to modify if needed
